{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9b4922-bfc4-45ce-93e9-7605c597bce9",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this section we will demonstrate how to perform the two types of model serving to test our prediction services: online and batch. \n",
    "\n",
    "In a typical MLOps setup, you would deploy a training pipeline and some kind of serving pipeline (either online or batch). \n",
    "\n",
    "* Batch: we will configure a batch prediction job with Explainable AI for feature attributions on the prediction values, as well as automated model monitoring to detect for training / serving data drift. \n",
    "* Online: we will configure an endpoint for online prediction and how to upload a model to the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b3824-5055-43f0-8d78-e4ae2b63eb06",
   "metadata": {},
   "source": [
    "# Create a batch prediction job\n",
    "We will cover how to deploy this model to an endpoint for online prediction in the deployment notebook, but let's cover how to configure a batch prediction job using an AutoML model. \n",
    "\n",
    "1. From the model screen, select Batch Predict. You can also navigate to the batch predictions section of Vertex AI \n",
    "2. Click Create Batch Prediction\n",
    "![](./automl_batch_config.png)\n",
    "3. On model monitoring, select Training dataset as the baseline for comparison, and use the default threshold values. Add any extra emails you may want to get an alert.\n",
    "![](./model_monitor.png)\n",
    "\n",
    "Great! You have successfully configured automated feature explainations on a batch prediction job, along with automated model monitoring for training / serving skew for your batch data. \n",
    "\n",
    "Once the job finishes, you can return and inspect the monitored features and monitored properties. \n",
    "\n",
    "## Monitoring Results\n",
    "Navigate to Batch Prediction from the Vertex AI sidebar, and select the job once it has completed. \n",
    "\n",
    "You can now investigate the results of the feature monitoring by selecting monitored features at the top menu.\n",
    "![](./monitor_feature.png) \n",
    "If any alerts were thrown, you would see them here. You may have also received an email depending on the configuration. \n",
    "\n",
    "If you navigate to monitoring properties, you can understand what the monitoring objective was, and which baseline training data source was used for the comparison to detect if drift had occured. \n",
    "\n",
    "## Explainable AI - Results\n",
    "Now let's explore the local prediction explanations that are available in BigQuery. These will be located where you defined them when configuring the batch prediction job earlier - if you had not specified the dataset or table, a new one would have been created. \n",
    "\n",
    "If you navigate to BigQuery and expand the dataset where you had specified the explainability results to be written to.\n",
    "\n",
    "You'll notice now, you can see explanations as a nested field, expand and you'll see attributions and feature attributions for each of your prediction values. \n",
    "![](./explain_schema.png)\n",
    "You now have both an understanding of the feature importance both at a global (to the overall model) level, and at the local (individual predictions) level. \n",
    "\n",
    "Navigate to preview in BigQuery or execute a few queries to see the explanations. You'll see an attribution value for each of the features used for prediction. \n",
    "![](./explain_values.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6668d8-07f6-4b37-86d0-075c5f0ae553",
   "metadata": {},
   "source": [
    "## Online Prediction\n",
    "\n",
    "Now, let's see how we would deploy a model to an endpoint for online prediction, effectively packaging it up as an API that is always available, with the ability to scale up and down and split traffic to endpoints. \n",
    "\n",
    "### Create an endpoint\n",
    "Navigate to endpoints in Vertex AI\n",
    "\n",
    "Click on Create Endpoint\n",
    "\n",
    "Define your endpoint\n",
    "![](./define_endpoint.png)\n",
    "\n",
    "Now, let's deploy your model to the endpoint\n",
    "![](./deploy.png)\n",
    "\n",
    "Go to the endpoints and try to ping the endpoint - can you figure out how to get a reponse?\n",
    "![](./ping_endpoint.png) \n",
    "\n",
    "Remember to undeploy the model and delete the endpoint once you are done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddff372-5091-4c91-be1e-bdd2fdc06db6",
   "metadata": {},
   "source": [
    "# Alternative: use SDK + prebuilt sk-learn container image for prediction\n",
    "* list of prebuilt containers: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "* import with explanations: https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-feature-based#scikit-learn-and-xgboost-pre-built-containers\n",
    "us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118b035-0f9a-4480-a977-2ef98216b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload model to endpoint with prebuilt container\n",
    "IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\"\n",
    "MODEL_DISPLAY_NAME=\"sklearn_ga\"\n",
    "\n",
    "model = vertex_ai.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=MODEL_ARTIFACTS_REPOSITORY,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    "    serving_container_ports=[5000],\n",
    "    sync=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae1973-5c56-47d5-bf57-c2267a6fd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create endpoint\n",
    "ENDPOINT_DISPLAY_NAME=\"sklearn_ga\"\n",
    "\n",
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=ENDPOINT_DISPLAY_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560067f2-5657-4ef0-b16b-b4db2f7891b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.deploy(\n",
    "    model=model,\n",
    "    deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "    machine_type=\"n1-standard-4\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
