{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3aca892-9eb9-46c3-b1fe-f0f9704784b1",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this section, you will create a managed dataset in Vertex AI, train an AutoML model, evaluate the model, and examine the parameters in the logs to understand how to recreate the model if needed.\n",
    "\n",
    "## Create Vertex AI Managed Dataset\n",
    "In order to use Vertex AI AutoML, you must first create a managed dataset. Note - we are using the UI for these exercises, but all of these tasks can also be accomplished using the Vertex AI Python SDK. \n",
    "\n",
    "1. In Vertex AI console, navigate to Datasets\n",
    "2. Select \"Create\" and give your dataset a name, select Data Type as <b>Tabular</b>, <b>Regression / Classification</b> as the Objective. When choosing your region, choose the same region that you created your Vertex AI workbench managed notebook in, to ensure consistencies in regions. Click \"Create\"\n",
    "![](./managed_dataset.png)\n",
    "3. Now, let's add data to the this dataset. Choose \"Select a table or view from BigQuery\". Type in the path to the previously created training table in BigQuery: the format will be {PROJECT_ID}.{DATASET}.{TABLE}, then select create. You should see the information about this dataset now available:\n",
    "![](./dataset_created.png)\n",
    "You can now also click on \"Generate Statistics\" to generate a data profile around the data.\n",
    "\n",
    "Alternatively, you can use the Vertex AI SDK to create the dataset\n",
    "\n",
    "Link to documentation: https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/create-dataset#aiplatform_create_dataset_tabular_bigquery_sample-python\n",
    "\n",
    "See example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a27917-0f30-41fc-8491-544d29ca0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_import_dataset_tabular_bigquery_sample(\n",
    "    display_name: str,\n",
    "    project: str,\n",
    "    location: str,\n",
    "    bq_source: str,\n",
    "):\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    dataset = aiplatform.TabularDataset.create(\n",
    "        display_name=display_name,\n",
    "        bq_source=bq_source,\n",
    "    )\n",
    "\n",
    "    dataset.wait()\n",
    "\n",
    "    print(f'\\tDataset: \"{dataset.display_name}\"')\n",
    "    print(f'\\tname: \"{dataset.resource_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc9490-80e8-4239-8500-8088a3d750ed",
   "metadata": {},
   "source": [
    "## Model Training with AutoML\n",
    "1. Click on \"Train New Model\"\n",
    "2. Select Classification as the objective, choose AutoML as the training method\n",
    "4. Select train a new model, give the model a unique name, select label as the Target Column. Optionally, you can export a test dataset to BigQuery (we also have a separate test dataset reserved, so no need to do this). If you expand advanced options, you can also choose to change some of the default configurations. \n",
    "5. For Training Options, proceed with the default settings (unless you want to change them)\n",
    "6. Provide a budget of 3 node hours, and enable early stopping\n",
    "7. Click Start Training\n",
    "8. Navigate to Training on the Vertex AI sidebar - you'll see your job has successfully started, and you can drill into it to get specific details and status. \n",
    "![](./automl_train.png)\n",
    "\n",
    "Alternatively, you can use the Vertex AI SDK to train the model\n",
    "\n",
    "Link to documentation: https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/train-model\n",
    "\n",
    "See example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5447b29-97c1-42e3-8ca7-da78cceff3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_pipeline_tabular_classification_sample(\n",
    "    project: str,\n",
    "    display_name: str,\n",
    "    dataset_id: str,\n",
    "    location: str = \"us-central1\",\n",
    "    model_display_name: str = None,\n",
    "    target_column: str = \"target_column\",\n",
    "    training_fraction_split: float = 0.8,\n",
    "    validation_fraction_split: float = 0.1,\n",
    "    test_fraction_split: float = 0.1,\n",
    "    budget_milli_node_hours: int = 8000,\n",
    "    disable_early_stopping: bool = False,\n",
    "    sync: bool = True,\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    tabular_classification_job = aiplatform.AutoMLTabularTrainingJob(\n",
    "        display_name=display_name, optimization_prediction_type=\"classification\"\n",
    "    )\n",
    "\n",
    "    my_tabular_dataset = aiplatform.TabularDataset(dataset_name=dataset_id)\n",
    "\n",
    "    model = tabular_classification_job.run(\n",
    "        dataset=my_tabular_dataset,\n",
    "        target_column=target_column,\n",
    "        training_fraction_split=training_fraction_split,\n",
    "        validation_fraction_split=validation_fraction_split,\n",
    "        test_fraction_split=test_fraction_split,\n",
    "        budget_milli_node_hours=budget_milli_node_hours,\n",
    "        model_display_name=model_display_name,\n",
    "        disable_early_stopping=disable_early_stopping,\n",
    "        sync=sync,\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    print(model.uri)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26292d57-5dfb-403e-9ad8-bf2cf4d8e6a9",
   "metadata": {},
   "source": [
    "Nice! Let this job run - in the meantime, head over to the BQML notebook and continue with the other training exercises whilst this job runs. \n",
    "\n",
    "## Evaluate model\n",
    "Once the model has finished training, click on it to explore the evaluation results. \n",
    "\n",
    "You can see the evaluation metrics, as well as the feature attributions - which features were most important to the model prediction results. \n",
    "\n",
    "![](./automl_eval.png)\n",
    "\n",
    "If you navigate to the Vertex AI model registry, you will also see that the model is now available in the model registry. \n",
    "\n",
    "Alternatively, you can use the Vertex AI SDK to evaluate the model\n",
    "\n",
    "Link to documentation: https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/evaluate-model\n",
    "\n",
    "See example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b214a-4ad6-4a56-a5b2-4d837150105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "\n",
    "def get_model_evaluation_tabular_classification_sample(\n",
    "    project: str,\n",
    "    model_id: str,\n",
    "    evaluation_id: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    \"\"\"\n",
    "    To obtain evaluation_id run the following commands where LOCATION\n",
    "    is the region where the model is stored, PROJECT is the project ID,\n",
    "    and MODEL_ID is the ID of your model.\n",
    "\n",
    "    model_client = aiplatform.gapic.ModelServiceClient(\n",
    "        client_options={\n",
    "            'api_endpoint':'LOCATION-aiplatform.googleapis.com'\n",
    "            }\n",
    "        )\n",
    "    evaluations = model_client.list_model_evaluations(parent='projects/PROJECT/locations/LOCATION/models/MODEL_ID')\n",
    "    print(\"evaluations:\", evaluations)\n",
    "    \"\"\"\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    name = client.model_evaluation_path(\n",
    "        project=project, location=location, model=model_id, evaluation=evaluation_id\n",
    "    )\n",
    "    response = client.get_model_evaluation(name=name)\n",
    "    print(\"response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f3f79-8b73-418e-b757-06af34a5fd1a",
   "metadata": {},
   "source": [
    "## AutoML Parameters\n",
    "Source: https://cloud.google.com/automl-tables/docs/logging\n",
    "\n",
    "Once the training job is finished, you can navigate to get the parameters from the logs.\n",
    "\n",
    "* Navigate to the training job and click on it\n",
    "* Select Version Details\n",
    "* Next to Model hyperparameters, click on Model\n",
    "* This will launch into Cloud Logging - click Run Query\n",
    "* Copy the results to clipboard and paste into a new screen\n",
    "\n",
    "\n",
    "We can see it was a boosted tree model, and we can use these hyperparameters to recreate our own boosted tree if we didn't want to use the AutoML model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e6e77-e14e-4510-ab1c-d4f4b5e421b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "\n",
    "{\n",
    "  \"insertId\": \"jpknobf3gy1i0\",\n",
    "  \"jsonPayload\": {\n",
    "    \"@type\": \"type.googleapis.com/google.cloud.automl.master.TablesModelStructure\",\n",
    "    \"modelParameters\": [\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l2\": 0,\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"num_trees\": 50,\n",
    "          \"l1\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"l1\": 3,\n",
    "          \"num_trees\": 50,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"l2\": 0,\n",
    "          \"max_tree_depth\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l1\": 3,\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l2\": 0,\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"num_trees\": 50\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l1\": 3,\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"l2\": 0,\n",
    "          \"num_trees\": 50\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"l2\": 0,\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l1\": 3,\n",
    "          \"num_trees\": 50,\n",
    "          \"tree_complexity\": 0.10000000149011612\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l1\": 3,\n",
    "          \"l2\": 0.30000001192092896,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"tree_complexity\": 0.30000001192092896,\n",
    "          \"num_trees\": 50\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l2\": 0.30000001192092896,\n",
    "          \"tree_complexity\": 0.30000001192092896,\n",
    "          \"num_trees\": 50,\n",
    "          \"l1\": 3,\n",
    "          \"model_type\": \"boosted_trees\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l1\": 3,\n",
    "          \"tree_complexity\": 0.30000001192092896,\n",
    "          \"num_trees\": 50,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"l2\": 0.30000001192092896\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l2\": 0.30000001192092896,\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"tree_complexity\": 0.30000001192092896,\n",
    "          \"num_trees\": 50,\n",
    "          \"l1\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"num_trees\": 50,\n",
    "          \"tree_complexity\": 0.30000001192092896,\n",
    "          \"l2\": 0.30000001192092896,\n",
    "          \"l1\": 3,\n",
    "          \"model_type\": \"boosted_trees\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"l2\": 0,\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"tree_complexity\": 1,\n",
    "          \"num_trees\": 50,\n",
    "          \"max_tree_depth\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"tree_complexity\": 1,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"num_trees\": 50,\n",
    "          \"l2\": 0,\n",
    "          \"max_tree_depth\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l2\": 0,\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"tree_complexity\": 1,\n",
    "          \"num_trees\": 50,\n",
    "          \"model_type\": \"boosted_trees\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l2\": 0,\n",
    "          \"tree_complexity\": 1,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"num_trees\": 50\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l2\": 0,\n",
    "          \"tree_complexity\": 1,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"num_trees\": 50\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"tree_complexity\": 0.30000001192092896,\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l2\": 0.30000001192092896,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"num_trees\": 100,\n",
    "          \"l1\": 0.30000001192092896\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"tree_complexity\": 0.30000001192092896,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"num_trees\": 100,\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l2\": 0.30000001192092896\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l2\": 0.30000001192092896,\n",
    "          \"num_trees\": 100,\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"tree_complexity\": 0.30000001192092896\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"num_trees\": 100,\n",
    "          \"l2\": 0.30000001192092896,\n",
    "          \"tree_complexity\": 0.30000001192092896\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l2\": 0.30000001192092896,\n",
    "          \"l1\": 0.30000001192092896,\n",
    "          \"num_trees\": 100,\n",
    "          \"tree_complexity\": 0.30000001192092896,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"max_tree_depth\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"num_trees\": 250,\n",
    "          \"l1\": 1,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"l2\": 0.10000000149011612,\n",
    "          \"max_tree_depth\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l1\": 1,\n",
    "          \"l2\": 0.10000000149011612,\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"num_trees\": 250,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"max_tree_depth\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l2\": 0.10000000149011612,\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"l1\": 1,\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"num_trees\": 250,\n",
    "          \"model_type\": \"boosted_trees\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"l2\": 0.10000000149011612,\n",
    "          \"num_trees\": 250,\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"model_type\": \"boosted_trees\",\n",
    "          \"l1\": 1,\n",
    "          \"max_tree_depth\": 3\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"hyperparameters\": {\n",
    "          \"tree_complexity\": 0.10000000149011612,\n",
    "          \"l1\": 1,\n",
    "          \"num_trees\": 250,\n",
    "          \"l2\": 0.10000000149011612,\n",
    "          \"max_tree_depth\": 3,\n",
    "          \"model_type\": \"boosted_trees\"\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"resource\": {\n",
    "    \"type\": \"cloudml_job\",\n",
    "    \"labels\": {\n",
    "      \"project_id\": \"leedeb-experimentation\",\n",
    "      \"job_id\": \"1734134346165518336\",\n",
    "      \"region\": \"us-central1\"\n",
    "    }\n",
    "  },\n",
    "  \"timestamp\": \"2023-01-18T15:26:57.209204Z\",\n",
    "  \"severity\": \"INFO\",\n",
    "  \"labels\": {\n",
    "    \"log_type\": \"automl_tables\"\n",
    "  },\n",
    "  \"logName\": \"projects/leedeb-experimentation/logs/automl.googleapis.com%2Fmodel\",\n",
    "  \"receiveTimestamp\": \"2023-01-18T18:34:08.777423339Z\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf9fd1-dd5f-4b97-b64e-de05c740eec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
