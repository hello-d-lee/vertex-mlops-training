{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a107339-f859-41b4-b105-5985dbd1bf38",
   "metadata": {},
   "source": [
    "# Overview\n",
    "These notebooks will demonstrate the different ways to train a model in various services (AutoML, BQML, Databricks) and export that model to the model registry to deploy it on a Vertex AI endpoint for online prediction\n",
    "\n",
    "* Setup notebook - required infrastructure and datasets that will be used in the subsequent notebooks\n",
    "* AutoML notebook - train a Vertex AI AutoML model, and then get the parameters for that model from the logs after training\n",
    "* BQML notebook - train model using BigQuery ML, check the artifacts and export to the Vertex AI model registry \n",
    "* Vertex Workbench managed notebook - how to train the model using Vertex AI's managed notebooks\n",
    "* Deployment & cleanup notebook - create an endpoint for each type of model, deploy each model to the endpoint, test the prediction service. Finally, delete running resources to avoid incurring extra costs.  \n",
    "\n",
    "As a next step, show how to use Vertex AI pipelines for end to end MLOps orchestration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7375e2-cda7-4bc2-a295-93ad86ffd886",
   "metadata": {},
   "source": [
    "## Create the required datasets \n",
    "We'll be using a publicly available Google Analytics dataset for the exercises, you can read more about it here: \n",
    "* https://support.google.com/analytics/answer/7586738?hl=en&ref_topic=3416089#zippy=%2Cin-this-article\n",
    "* Also used here: https://cloud.google.com/bigquery-ml/docs/create-machine-learning-model\n",
    "\n",
    "### Before you begin\n",
    "* Make sure that billing is enabled for your Cloud project. Learn how to check if billing is enabled on a project.\n",
    "\n",
    "* BigQuery is automatically enabled in new projects. To activate BigQuery in a pre-existing project, go to\n",
    "Enable the BigQuery API.\n",
    "\n",
    "### Create a BQ Dataset\n",
    "The first step is to create a BigQuery dataset to store your ML model. To create your dataset:\n",
    "\n",
    "1. In the Google Cloud console, go to the BigQuery page.\n",
    "2. In the navigation panel, in the Resources section, click your project name.\n",
    "3. On the right side, in the details panel, click Create dataset.\n",
    "4. On the Create dataset page:\n",
    "* For Dataset ID, enter a unique name (this lab uses bq_databricks_vertex).\n",
    "* For Data location, choose United States (US). Currently, the public datasets are stored in the US multi-region location. For simplicity, you should place your dataset in the same location.\n",
    "![](./create_dataset.png)\n",
    "5. Leave all of the other default settings in place and click Create dataset.\n",
    "\n",
    "Make sure to keep a note of the name you choose for your dataset, as you'll be using it throughout the remaining exercises. \n",
    "\n",
    "Next, create the tables in your newly created dataset - please note, your PROJECT, DATASET may be different from the below - you will need to change before running in the console.\n",
    "\n",
    "Navigate to the BigQuery console and open a new editor tab. There, use the following code snippets below to create the training and testing tables. Remember to change the project and dataset names to your own!\n",
    "\n",
    "1. First, create the training dataset\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TABLE `leedeb-experimentation.bq_databricks_vertex.training_data` AS\n",
    "SELECT\n",
    "  IF(totals.transactions IS NULL, 0, 1) AS label,\n",
    "  IFNULL(device.operatingSystem, \"\") AS os,\n",
    "  device.isMobile AS is_mobile,\n",
    "  IFNULL(geoNetwork.country, \"\") AS country,\n",
    "  IFNULL(totals.pageviews, 0) AS pageviews\n",
    "FROM\n",
    "  `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n",
    "WHERE\n",
    "  _TABLE_SUFFIX BETWEEN '20160801' AND '20170630'\n",
    "````\n",
    "\n",
    "2. Next, create the testing dataset\n",
    "```sql\n",
    "CREATE OR REPLACE TABLE `leedeb-experimentation.bq_databricks_vertex.testing_data` AS\n",
    "SELECT\n",
    "  IF(totals.transactions IS NULL, 0, 1) AS label,\n",
    "  IFNULL(device.operatingSystem, \"\") AS os,\n",
    "  device.isMobile AS is_mobile,\n",
    "  IFNULL(geoNetwork.country, \"\") AS country,\n",
    "  IFNULL(totals.pageviews, 0) AS pageviews\n",
    "FROM\n",
    "  `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n",
    "WHERE\n",
    "  _TABLE_SUFFIX BETWEEN '20170701' AND '20170801'\n",
    "```\n",
    "\n",
    "You should now see the two tables created under your dataset. \n",
    "\n",
    "![](./tables_created.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502f996-d5ee-4efa-801a-0b572b403883",
   "metadata": {},
   "source": [
    "## Create Vertex AI Managed Notebook\n",
    "Finally, let's create the Vertex AI Workbench Managed Notebook so it is ready to use for the exercises. \n",
    "1. Navigate to Vertex AI from the GCP console\n",
    "2. Click on Workbench on the menu, and click on Managed Notebooks\n",
    "3. Make sure you're in a us region - as our sample dataset is in the US regions - and click on New Notebook\n",
    "4. Give your notebook a name and select Service Account under Permission, feel free to customize other features under Advanced if desired such as idle shut down time, instance size, etc. \n",
    "![](./managed_notebook.png) \n",
    "\n",
    "\n",
    "Now, you have your resources created - you can move onto the exercises! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472e04d-7f76-4a83-a3d6-4960e696d9bf",
   "metadata": {},
   "source": [
    "## Create a GCS Bucket\n",
    "If you don't have an existing Google Cloud Storage bucket, please create one in the same region where you have created your vertex AI managed notebook and use the default storage settings. \n",
    "![](./bucket_models.png)\n",
    "Once the bucket is created, create a models folder within it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41796f-e4ec-482a-adf5-ed45ae4fe15e",
   "metadata": {},
   "source": [
    "## Service Account Permissions\n",
    "You may need to add some extra permissions to the compute engine default service account, depending on how it was already set up. \n",
    "* Vertex AI Admin\n",
    "* GCS Storage Admin\n",
    "* BigQuery Admin\n",
    "* Notebooks Admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b647205-ca5d-43e3-b8ca-b5d5b0b8b3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
